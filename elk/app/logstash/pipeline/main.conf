# https://www.elastic.co/guide/en/logstash/current/plugins-inputs-syslog.html
input {
  syslog  { port => 514 }
  beats   { port => 515 }
}

filter {
  ################
  # Cisco Syslog #
  ################
  # matching syslog from cisco devices
  #
  #################################################
  # device configuration
  # expecting following cisco configs for logging:
  #
  # logging source-interface [loopbacke]
  # service timestamps log datetime localtime msec show-timezone year
  # ip ssh logging events
  # login on-failure log
  # login on-success log
  # archive
  #   log config
  #   hidekeys
  #   notify syslog
  #   logging enable
  # logging host 1.2.3.4 transport udp port 514 session-id hostname sequence-num-session
  #
  ##################################################
  # transfrom log severity to worded value in Kibana
  # a nice to have feature
  # create scripted field "app.loglevel" from "app.severity"
  #
  # def n = doc['app.severity'].value;
  # if (n == 0) { emit("Emergency"); }
  # else if (n == 1) { emit("Alert"); }
  # else if (n == 2) { emit("Critical"); }
  # else if (n == 3) { emit("Error"); }
  # else if (n == 4) { emit("Warning"); }
  # else if (n == 5) { emit("Notice"); }
  # else if (n == 6) { emit("Informational"); }
  # else if (n == 7) { emit("Debug"); }
  # else { emit(""); }
  #
  ####################################
  # kibana template custom date format
  # app.timestamp: MMM  d yyyy HH:mm:ss.SSS zzz||MMM dd yyyy HH:mm:ss.SSS zzz
  #
  if [message] =~ "^<[0-9]+>[0-9]+: \[syslog@9 s_sn=.*" {
    grok {
      patterns_dir => ["/usr/share/logstash/pipeline/patterns"]

      #index name
      add_field => [ "type", "syslog" ]
      add_field => [ "dataset", "cisco" ]
      add_field => [ "namespace", "og.networks" ]

      # cisco syslog
      # examples)
      # <189>347: [syslog@9 s_sn="346" s_id ="rtr-csr1000:514"]: Mar 12 2024 08:15:14.949 UTC: %SEC_LOGIN-5-LOGIN_SUCCESS: Login Success [user: cisco] [Source: LOCAL] [localport: 0] at 08:15:14 UTC Tue Mar 12 2024
      # <190>349: [syslog@9 s_sn="348" s_id ="rtr-csr1000:514"]: Mar 12 2024 08:37:43.380 UTC: %SYS-6-LOGOUT: User cisco has exited tty session 0()
      match => { "message" => '<%{NUMBER}>%{NUMBER}: \[%{NOTSPACE:app.facility} s_sn="%{NUMBER:app.cisco.sequence}" s_id ="%{HOSTNAME:app.host.name}:%{NUMBER:app.host.dst.port}"]: \*?%{SYSLOG_YEAR:app.timestamp}: %%{FACILITY_SEVERITY_CODE}: %{GREEDYDATA:app.message}' }

      # else
      match => { "message" => "%{GREEDYDATA:app.message}" }

      add_field => [ "app.host.src.ip", "%{[host][ip]}" ]
      remove_field => [ "app.remove", "message", "[host]" ]
    }

    # when configuration changes occur AKA "CFGLOG_LOGGEDCMD"
    # create field for user and command used
    if [app.cisco.mnemonic] == "CFGLOG_LOGGEDCMD" {
      grok {
        match => { "[app.message]" => "^User:%{NOTSPACE:app.cisco.user}.*command:%{GREEDYDATA:app.cisco.command}" }
      }
    }

    # when user logs attempts to login (success or failed) AKA "SEC_LOGIN"
    # create field for user, localport, reason (if failed)
    if [app.cisco.facility] == "SEC_LOGIN" {
      grok {
        patterns_dir => ["/usr/share/logstash/pipeline/patterns"]
        
        # examples)
        # Login Success [user: cisco] [Source: 10.0.20.39] [localport: 22] at 07:52:48 UTC Tue Mar 12 2024
        # Login Success [user: cisco] [Source: LOCAL] [localport: 0] at 08:15:14 UTC Tue Mar 12 2024
        # Login failed [user: cisco] [Source: LOCAL] [localport: 0] [Reason: Login Authentication Failed - BadPassword] at 09:25:47 UTC Mon Mar 18 202
        match => { "[app.message]" => "^Login.*user: %{NOTRIGHTBRACKET:app.cisco.user}.*Source: (%{IP:app.cisco.login.source})?.*localport: %{INT:app.cisco.login.localport}\]( \[Reason: %{NOTRIGHTBRACKET:app.cisco.login.failed.reason}\])?.*" }
      }
    }

    if [app.cisco.mnemonic] == "LOGOUT" {
      grok {
        patterns_dir => ["/usr/share/logstash/pipeline/patterns"]
        
        # examples)
        # User cisco has exited tty session 0()
        match => { "[app.message]" => "^User %{WORD:app.cisco.user}.*session %{INT:app.cisco.login.tty}.*\(%{IP:app.cisco.login.source}?\)$" }
      }
    }
    
    # keep field type IP and remove case where text is not an IP
    #if ([app.cisco.mnemonic] == "LOGOUT" or [app.cisco.facility] == "SEC_LOGIN") and  [app.cisco.login.source] == "LOCAL" {
    #  mutate { remove_field => [ "app.cisco.login.source" ] }
    #}

    if [app.cisco.facility] == "SSH" {
      grok {
        patterns_dir => ["/usr/share/logstash/pipeline/patterns"]
        
        # examples)
        # SSH2 Session request from 10.0.20.39 (tty = 0) using crypto cipher 'aes128-ctr', hmac 'hmac-sha2-256-etm@openssh.com' Succeeded
        # User 'cisco' authentication for SSH2 Session from 10.0.20.39 (tty = 0) using crypto cipher 'aes128-ctr', hmac 'hmac-sha2-256-etm@openssh.com' Succeeded
        # SSH2 Session from 10.0.20.39 (tty = 0) for user 'cisco' using crypto cipher 'aes128-ctr', hmac 'hmac-sha2-256-etm@openssh.com' closed
        match => { "[app.message]" => "(User '%{WORD:app.cisco.user}')?.*from %{IP:app.cisco.login.source}.*tty = %{INT:app.cisco.login.tty}(.*user '%{WORD:app.cisco.user}')?.*cipher '%{NOTSPACE:app.cisco.login.cipher}'.*hmac '%{NOTSPACE:app.cisco.login.hmac}'.*" }
      }
    }
  }

  #########
  # nginx #
  #########
  # syslog from nginx web/proxy

  if [process][name] == "nginx" {
    grok {
      patterns_dir => ["/usr/share/logstash/pipeline/patterns"]
      
      # index name
      add_field => [ "type", "syslog" ]
      add_field => [ "dataset", "nginx" ]
      add_field => [ "namespace", "og.networks" ]

      # expected match
      match => { "message" => "~%{NOT_TILDE:app.nginx.version}~%{IP:app.src.ip}~%{POSINT:app.src.port}~%{IP:app.dst.ip}~%{POSINT:app.dst.port}~%{NOT_TILDE:app.timestamp}~%{WORD:app.http.method}~%{WORD:app.http.scheme}~%{NOT_TILDE:app.http.server}~%{NOT_TILDE:app.http.path}~%{NOT_TILDE:app.http.query_string}~%{NOT_TILDE:app.http.version}~%{POSINT:app.http.status}~%{POSINT:app.http.bytes}~%{NOT_TILDE:app.http.content_type}~%{NOT_TILDE:app.http.ssl.cipher}~%{NOT_TILDE:app.http.ssl.version}~%{NOT_TILDE:app.http.ssl.session_id}~%{NOT_TILDE:app.http.referer}~%{NOT_TILDE:app.http.user_agent}%{GREEDYDATA}" }

      #else
      match => { "message" => "%{GREEDYDATA:app.message}" }

      remove_field => ["message"]
    }

    mutate {
      add_field => [ "app.host.src.ip", "%{[host][ip]}" ]
      remove_field => ["[host][ip]"]
    }

    if [app.http.server]        == "-" { mutate { remove_field => ["app.http.server"] } }
    if [app.http.query_string]  == "-" { mutate { remove_field => ["app.http.query_string"] } }
    if [app.http.ssl.cipher]    == "-" { mutate { remove_field => ["app.http.ssl.cipher"] } }
    if [app.http.ssl.version]   == "-" { mutate { remove_field => ["app.http.ssl.version"] } }
    if [app.http.content_type]  == "-" { mutate { remove_field => ["app.http.content_type"] } }
    if [app.http.scheme]        == "-" { mutate { remove_field => ["app.http.scheme"] } }
  }


  #################
  # redcom sigma  #
  #################
  # syslog from REDCOM Sigama VoIP call manager
  #
  ############################
  # configure syslog in redcom
  # My Apps -> App Gallary -> Network Configuration -> Syslog Client -> Edit Syslog Client
  # Type: CDR Only
  # Enable UDP: slide button on
  # UDP Destination: IP of server
  #
  ####################################
  # kibana template custom date format
  # yyyy-MM-dd HH:mm:ss.SSSSSSx|yyyy-MM-dd HH:mm:ss.SSSSSx
  #
  if [message] =~ "(.*~){9}.*" {
    grok {
      patterns_dir => ["/usr/share/logstash/pipeline/patterns"]

      #index name
      add_field => [ "type", "syslog" ]
      add_field => [ "dataset", "redcom" ]
      add_field => [ "namespace", "og.networks" ]

      # example logs)
      # 6461904~SNN 646190 Main-6461904~3023572162~NA~seized~0~NA~2024-03-02 06:31:53.828327+00~2024-03-02 06:31:49.978753+00
      # 6461904~SNN 646190 Main-6461904~play~Announcement~answered~0~2024-03-02 06:31:35.062582+00~2024-03-02 06:31:37.476409+00~2024-03-02 06:31:34.999555+00
      match => { "message" => "%{NOT_TILDE:phone.src.num}~%{NOT_TILDE:phone.src.name}~%{NOT_TILDE:phone.dst.num}~%{NOT_TILDE:phone.dst.name}~%{NOT_TILDE:call.status}~%{NOT_TILDE:call.var}~%{NOT_TILDE:call.answer}~%{NOT_TILDE:call.end}~%{NOT_TILDE:call.ring}%{GREEDYDATA:app.message}" }

      # all else
      match => { "message" => "%{GREEDYDATA:syslog_message}" }
    }
    
    # break out origin host:port into separate fields
    grok {
      match => { "[log][source][address]" => "%{IP:src.ip}:%{POSINT:src.port}" }
      remove_field => ["[log][source][address]"]
    }
      
    # field call.answer should be a datetime format
    # an unanswered call yields text "NA"
    # remove field for unanswered call to prevent malform data types
    # check if field exists then check if value is "NA"
    if [call.answer] and [call.answer] == "NA" {
      mutate { remove_field => ["call.answer"] }
    }
  }
  
  ####################
  # tftp server logs #
  ####################
  # matching syslog from tftpd
  #
  if [type] == "tftp" {
    grok {
      patterns_dir => ["/usr/share/logstash/pipeline/patterns"]

      #file read/write
      match => { "message" => "%{SYSLOGTIMESTAMP} tftp %{WORD:SOURCE}.%{LOGLEVEL:LOGLEVEL} in.tftpd\[%{NUMBER}\]: %{WORD:OP} from %{IP:SRC_IP} filename %{FILE:FILE}" }

      #else
      match => { "message" => "%{GREEDYDATA:syslog_message}" }
    }
  }
  
  #################
  # endlessh logs #
  #################
  # matching syslog from endless ssh tarpit
  #
  if [fields][service] == "endlessh" {
    grok {
      patterns_dir => ["/usr/share/logstash/pipeline/patterns"]
      
      # index name
      add_field => [ "type", "syslog" ]
      add_field => [ "dataset", "endlessh" ]
      add_field => [ "namespace", "og.networks" ]

      # match syslog
      match => { "message" => ".* %{TIMESTAMP_ISO8601:app.timestamp} %{WORD:app.method}.*:ffff:%{IP:app.src.ip} port=%{NUMBER:app.src.port} fd=%{INT:app.fd} (n=.*|time=%{NUMBER:app.duration} bytes=%{INT:app.bytes})" }

      # else
      match => { "message" => "%{GREEDYDATA:app.message}" }

      remove_field => ["message"]
    }
  }

  ##############
  # bind9 logs #
  ##############
  # syslog for bind9 dns server
  #
  if [type] == "bind9" {
    grok {
      patterns_dir => ["/usr/share/logstash/pipeline/patterns"]

      # query
      match => { "message" => "%{BIND9_TIMESTAMP:timestamp_hst} %{WORD:category}: %{LOGLEVEL:severity}: client @%{NOTSPACE:client} %{IP:src_ip}#%{NUMBER:src_port} %{NOTSPACE} query: %{NOTSPACE:query} IN %{WORD:record} (%{NOTSPACE:flags} )?\(%{IP:srv_ip}\)" }
      
      # every else that's not a query
      match => { "message" => "%{BIND9_TIMESTAMP:timestamp_hst} %{WORD:category}: %{LOGLEVEL:severity}: %{GREEDYDATA:syslog_message}" }

      # all else
      match => { "message" => "%{GREEDYDATA:syslog_message}" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[type]}-%{[dataset]}-%{[namespace]}"
    action => "create"
    
    # auth
    #api_key => "ktO8c44BJqTQ7AaUdRHX:ru4-ejGVST6ol45Uq09eyw"
    #ssl => true
    user => "logstash"
    password => "LlS4eCk5MO7$Wssw"
  }
  stdout { codec => rubydebug }
}