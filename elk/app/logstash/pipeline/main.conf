input {
  #https://www.elastic.co/guide/en/logstash/current/plugins-inputs-syslog.html
  syslog  { port => 514 }
  beats   { port => 515 }
}

filter {
  ################
  # Cisco Syslog #
  ################
  # expecting following cisco configs for logging:
  #
  # logging source-interface [loopback]
  # service timestamps log datetime localtime msec show-timezone year
  # ip ssh logging events
  # login on-failure log
  # login on-success log
  # archive
  #   log config
  #   hidekeys
  #   notify syslog
  #   logging enable
  # logging host 10.0.20.30 transport udp port 514 session-id hostname sequence-num-session
  #
  ################################################
  # create scripted field loglevel from severity #
  ################################################
  # def n = doc['app.severity'].value;
  # if (n == 0) { emit("Emergency"); }
  # else if (n == 1) { emit("Alert"); }
  # else if (n == 2) { emit("Critical"); }
  # else if (n == 3) { emit("Error"); }
  # else if (n == 4) { emit("Warning"); }
  # else if (n == 5) { emit("Notice"); }
  # else if (n == 6) { emit("Informational"); }
  # else if (n == 7) { emit("Debug"); }
  # else { emit(""); }
  #
  ###################
  # kibana template #
  ###################
  # app.timestamp: MMM  d yyyy HH:mm:ss.SSS zzz||MMM dd yyyy HH:mm:ss.SSS zzz
  #
  if [message] =~ "^<[0-9]+>[0-9]+: \[.*" {
    grok {
      patterns_dir => ["/usr/share/logstash/pipeline/patterns"]

      #index name
      add_field => [ "type", "syslog" ]
      add_field => [ "dataset", "cisco" ]
      add_field => [ "namespace", "og.networks" ]

      #cisco syslog
      match => { "message" => '<%{NUMBER}>%{NUMBER}: \[%{NOTSPACE:app.facility} s_sn="%{NUMBER:app.cisco.sequence}" s_id ="%{HOSTNAME:app.host.name}:%{NUMBER:app.host.dst.port}"]: \*?%{SYSLOG_YEAR:app.timestamp}: %%{FACILITY_SEVERITY_CODE}: %{GREEDYDATA:app.message}' }

      #else
      match => { "message" => "%{GREEDYDATA:app.message}" }

      add_field => [ "app.host.src.ip", "%{[host][ip]}" ]
      remove_field => ["app.remove", "message", "[host]"]
    }

    #when configuration changes occur AKA "CFGLOG_LOGGEDCMD"
    #create field for user and command used
    if [app.cisco.mnemonic] == "CFGLOG_LOGGEDCMD" {
      grok {
        match => { "[app.message]" => "^User:%{NOTSPACE:app.cisco.user}.*command:%{GREEDYDATA:app.cisco.command}" }
      }
    }

    #when user logs attempts to login (success or failed) AKA "SEC_LOGIN"
    #create field for user, localport, reason (if failed)
    if [app.cisco.facility] == "SEC_LOGIN" {
      grok {
        patterns_dir => ["/usr/share/logstash/pipeline/patterns"]
        match => { "[app.message]" => "^Login.*user: %{NOTBACKSLASH:app.cisco.user}.*Source: %{NOTBACKSLASH:app.cisco.login.source}.*localport: %{NOTBACKSLASH:app.cisco.login.localport}.*(Reason: %{NOTBACKSLASH:app.cisco.login.failed.reason})?.*" }
      }
    }
  }

  #tftp server logs
  ##########################
  if [type] == "tftp" {
    grok {
      patterns_dir => ["/usr/share/logstash/pipeline/patterns"]

      #file read/write
      match => { "message" => "%{SYSLOGTIMESTAMP} tftp %{WORD:SOURCE}.%{LOGLEVEL:LOGLEVEL} in.tftpd\[%{NUMBER}\]: %{WORD:OP} from %{IP:SRC_IP} filename %{FILE:FILE}" }
      
      #basic syslog
      match => { "message" => "%{SYSLOGTIMESTAMP} tftp %{WORD:SOURCE}.%{LOGLEVEL:LOGLEVEL} %{GREEDYDATA:SYSLOG_MSG}" }

      #Else
      match => { "message" => "%{GREEDYDATA:syslog_message}" }
    }
  }
  
  #endlessh logs
  ##########################
  if [fields][service] == "endlessh" {
    grok {
      patterns_dir => ["/usr/share/logstash/pipeline/patterns"]
      
      #index name
      add_field => [ "type", "syslog" ]
      add_field => [ "dataset", "endlessh" ]
      add_field => [ "namespace", "og.networks" ]

      #match syslog
      match => { "message" => ".* %{TIMESTAMP_ISO8601:app.timestamp} %{WORD:app.method}.*:ffff:%{IP:app.src.ip} port=%{NUMBER:app.src.port} fd=%{INT:app.fd} (n=.*|time=%{NUMBER:app.duration} bytes=%{INT:app.bytes})" }

      #else
      match => { "message" => "%{GREEDYDATA:app.message}" }

      remove_field => ["message"]
    }
  }

  #bind9 logs
  ##########################
  if [type] == "bind9" {
    grok {
      patterns_dir => ["/usr/share/logstash/pipeline/patterns"]

      #query
      match => { "message" => "%{BIND9_TIMESTAMP:timestamp_hst} %{WORD:category}: %{LOGLEVEL:severity}: client @%{NOTSPACE:client} %{IP:src_ip}#%{NUMBER:src_port} %{NOTSPACE} query: %{NOTSPACE:query} IN %{WORD:record} (%{NOTSPACE:flags} )?\(%{IP:srv_ip}\)" }
      
      #every else that's not a query
      match => { "message" => "%{BIND9_TIMESTAMP:timestamp_hst} %{WORD:category}: %{LOGLEVEL:severity}: %{GREEDYDATA:syslog_message}" }

      #all else
      match => { "message" => "%{GREEDYDATA:syslog_message}" }
    }
  }

  #redcom logs
  ##########################
  #date format in elastic
  #yyyy-MM-dd HH:mm:ss.SSSSSSx|yyyy-MM-dd HH:mm:ss.SSSSSx
  #
  if [type] == "redcom" {
    grok {
      patterns_dir => ["/usr/share/logstash/pipeline/patterns"]

      #query
      match => { "message" => "%{RED_DELIM:phone.src.num}~%{RED_DELIM:phone.src.name}~%{RED_DELIM:phone.dst.num}~%{RED_DELIM:phone.dst.name}~%{RED_DELIM:call.status}~%{RED_DELIM:call.var}~%{RED_DELIM:call.answer}~%{RED_DELIM:call.end}~%{RED_DELIM:call.ring}%{GREEDYDATA:syslog_message}" }

      #all else
      match => { "message" => "%{GREEDYDATA:syslog_message}" }
    }
    
    #break out origin host:port into separate fields
    grok {
      match => { "[log][source][address]" => "%{IP:src.ip}:%{POSINT:src.port}" }
      remove_field => ["[log][source][address]"]
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[type]}-%{[dataset]}-%{[namespace]}"
    action => "create"
  }
  stdout {
    codec => rubydebug
  }
}